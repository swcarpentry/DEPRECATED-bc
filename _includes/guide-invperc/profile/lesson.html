<div id="s:invperc:profile" class="lesson">

  <p>
    Timing an entire program is a good way to find out if we're making things better or not,
    but some way to know where the time is going would be even better.
    The tool that will do that for us is called a <a href="glossary.html#profiler">profiler</a>
    because it creates a profile of a program's execution time,
    i.e.,
    it reports how much time is spent in each function in the program, or even on each line.
  </p>

  <p>
    There are two kinds of profilers.
    A <a href="glossary.html#deterministic-profiler">deterministic</a> profiler inserts instructions in a program
    to record the clock time at the start and end of every function.
    It doesn't actually modify the source code:
    instead,
    it adds those instructions behind the scenes
    after the code has been translated into something the computer can actually run.
    For example, suppose our program looks like this:
  </p>

<pre>
def swap(values):
    for i in range(len(values)/2):
        values[i], values[-1-i] = values[-1-i], values[i]

def upto(N):
    for i in xrange(1, N):
        temp = [0] * i
        swap(temp)

upto(100)
</pre>

  <p class="continue">
    A deterministic profiler would insert timing calls that worked like this:
  </p>

<pre>
def swap(values):
<span class="highlight">    _num_calls['swap'] += 1</span>
<span class="highlight">    _start_time = time.time()</span>
    for i in range(len(values)/2):
        values[i], values[-1-i] = values[-1-i], values[i]
<span class="highlight">    _total_time['swap'] += (time.time() - _start_time)</span>

def upto(N):
<span class="highlight">    _num_calls['upto'] += 1</span>
<span class="highlight">    _start_time = time.time()</span>
    for i in xrange(1, N):
        temp = [0] * i
        swap(temp)
<span class="highlight">    _total_time['upto'] += (time.time() - _start_time)</span>

<span class="highlight">_num_calls['swap'] = 0</span>
<span class="highlight">_total_time['swap'] = 0</span>
<span class="highlight">_num_calls['upto'] = 0</span>
<span class="highlight">_total_time['upto'] = 0</span>
upto(100)
</pre>

  <p class="continue">
    (Note that the profiler wouldn't actually change the source of our program;
    these extra operations are inserted after the program has been loaded into memory.)
  </p>

  <p>
    Once the program has been run,
    the profiler can use the two dictionaries <code>_num_calls</code> and <code>_total_time</code>
    to report the average running time per function call.
    Going further,
    the profiler can also keep track of which functions are calling which,
    so that (for example) it can report times for calls to <code>swap</code> from <code>upto</code>
    separately from calls to <code>swap</code> from some other function <code>downfrom</code>.
  </p>

  <p>
    The problem with deterministic profiling is that
    adding those timing calls changes the runtime of the functions being measured,
    since reading the computer's clock and recording the result both take time.
    The smaller the function's runtime, the larger the distortion.
    This can be avoided by using a <a href="glossary.html#statistical-profiler">statistical</a> profiler.
    Instead of adding timing calls to the code,
    it freezes the program every millisecond or so and makes a note of what function is running.
    Like any sampling procedure,
    this produces become more accurate as more data is collected,
    so statistical profilers work well on long-running programs,
    but can produce misleading results for short ones.
  </p>

  <p>
    Python's <code>cProfile</code> module is a deterministic profiler.
    It records times and call counts and saves data in a file for later analysis.
    We can use it to see where time goes in our initial list-of-lists invasion percolation program:
  </p>

<pre>
import cProfile, pstats
from invperc import main

cProfile.run('main(["51", "100", "127391"])', 'list.prof')
p = pstats.Stats('list.prof')
p.strip_dirs().sort_stats('time').print_stats()
</pre>

  <p>
    We start by importing <code>cProfile</code>, the actual profiling tool, on line 1.
    We also import <code>pstats</code>,
    a helper module for analyzing the data files <code>cProfile</code> produces.
  </p>

  <p>
    The second line imports the <code>main</code> function from our program.
    We give that starting point to <code>cProfile.run</code> on line 3,
    along with the name of the file we want the profiling results stored in.
    Notice that the call is passed as a string:
    <code>cProfile</code> uses Python's built-in <code>eval</code> function
    to run the command in this string,
    just as if we had typed it into the interpreter.
    Notice also that the arguments are passed as strings,
    since that's what <code>main</code> is expecting.
  </p>

  <p>
    Line 4 reads the profiling data back into our program
    and wraps it up in a <code>pstats.Stats</code> object.
    It may seem silly to write the data out only to read it back in,
    but the two activities are often completely separate:
    we can accumulate profiling data across many different runs of a program,
    then analyze it all at once.
  </p>

  <p>
    Finally, line 5 strips directory names off the accumulated data,
    sorts them according to run time, and prints the result.
    We strip directory names because all of the code we're profiling is in a single file;
    in larger programs, we'll keep the directory information
    (even though it makes the output a bit harder to read)
    so that we can separate <code>fred.calculate</code>'s running time from <code>jane.calculate</code>'s.
  </p>

  <p>
    Here's what the output looks like:
  </p>

<pre>
135 cells filled
Thu Jun 28 13:54:55 2012    list.prof

         697631 function calls in 0.526 CPU seconds

   Ordered by: internal time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
   339489    0.355    0.000    0.376    0.000 invperc.py:64(is_candidate)
      134    0.136    0.001    0.515    0.004 invperc.py:73(find_candidates)
   340029    0.021    0.000    0.021    0.000 {len}
     2601    0.005    0.000    0.005    0.000 random.py:160(randrange)
     7072    0.004    0.000    0.004    0.000 {range}
     2601    0.002    0.000    0.007    0.000 random.py:224(randint)
        1    0.001    0.001    0.008    0.008 invperc.py:39(fill_random_grid)
        1    0.001    0.001    0.001    0.001 invperc.py:27(create_grid)
        1    0.001    0.001    0.516    0.516 invperc.py:92(fill_grid)
     2735    0.000    0.000    0.000    0.000 {method 'random' of '_random.Random' objects}
     2652    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}
      134    0.000    0.000    0.000    0.000 random.py:259(choice)
      135    0.000    0.000    0.000    0.000 invperc.py:52(mark_filled)
        1    0.000    0.000    0.526    0.526 invperc.py:108(do_random)
        1    0.000    0.000    0.526    0.526 invperc.py:186(main)
        1    0.000    0.000    0.000    0.000 {function seed at 0x0221C2B0}
       40    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}
        1    0.000    0.000    0.000    0.000 random.py:99(seed)
        1    0.000    0.000    0.526    0.526 &lt;string&gt;:1(&lt;module&gt;)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
</pre>

  <p>
    The columns are the number of calls,
    the total time spent in that function,
    the time per call,
    the total cumulative time (i.e., the total time for that function and everything it calls),
    the cumulative time per call,
    and then which function the stat is for.
    As we can see,
    <code>is_candidate</code> accounts for two thirds of our runtime:
    if we want to make this program faster,
    that's what we should speed up.
  </p>

  <div class="box">
    <h3>Wall Clock Time vs. CPU Time</h3>

    <p>
      When profiling programs,
      particularly on machines that are running other applications at the same time,
      it's important to remember the distinction between
      <a href="glossary.html#cpu-time">CPU time</a>
      and
      <a href="glossary.html#wall-clock-time">wall-clock time</a>.
      The first is how much time the computer's processor actually spent running the program;
      the second is how long the program actually took to run.
      The two are different because the CPU has a lot of things to do
      besides running our program,
      even on a machine that's supposedly otherwise idle.
      The operating system itself needs time,
      for example,
      as do disk and network I/O.
    </p>

  </div>

</div>
