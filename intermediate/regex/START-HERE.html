<html>
  <head>
  </head>
  <body>

    <div class="toc">
      <ol>
        <li><a href="#s:basic">Simple Patterns</a></li>
        <li><a href="#s:operators">Operators</a></li>
        <li><a href="#s:mechanics">Under the Hood</a></li>
        <li><a href="#s:patterns">More Patterns</a></li>
        <li><a href="#s:tools">More Tools</a></li>
        <li><a href="#s:declarative">One Last Wrinkle</a></li>
        <li><a href="#s:summary">Summing Up</a></li>
      </ol>
    </div>

    <p>
      A couple of years after the Death Star exploded,
      a hot-shot reporter at the <cite>Daily Planet</cite> heard that children in the Shire
      were starting to act strangely.
      Our supervisor sent some grad students off to find out what was going on.
      Things didn't go so well for them, but their notebooks were recovered and later transcribed.
    </p>

    <p>
      Our job is to read 20 or 30 files,
      each of which contains several hundred measurements of background evil levels,
      and convert them into a uniform format for further processing.
      Each of the readings has the name of the site where the reading was taken,
      the date the reading was taken on,
      and of course the background evil level in millivaders.
      The problem is, these files are formatted in different ways.
      Here is the first one:
    </p>

<pre fixme="replace with diagram showing characters">
Site    Date    Evil (millivaders)
----    ----    ------------------
Baker 1 2009-11-17      1223.0
Baker 1 2010-06-24      1122.7
Baker 2 2009-07-24      2819.0
Baker 2 2010-08-25      2971.6
Baker 1 2011-01-05      1410.0
Baker 2 2010-09-04      4671.6
&#8942;        &#8942;               &#8942;
</pre>

    <p class="continue">
      A single tab character divides the fields in each row into columns.
      The site names contain spaces,
      and the dates are in international standard format:
      four digits for the year,
      two for the month,
      and two for the day.
    </p>

    <div class="box">
      <p class="boxtitle">
        Tabs vs. Spaces
      </p>

      <p class="fixme">
        Explain tabs and spaces.
      </p>
    </div>

    <p>
      Let's have a look at the second notebook:
    </p>

<pre fixme="replace with diagram showing characters">
Site/Date/Evil
Davison/May 22, 2010/1721.3
Davison/May 23, 2010/1724.7
Pertwee/May 24, 2010/2103.8
Davison/June 19, 2010/1731.9
Davison/July 6, 2010/2010.7
Pertwee/Aug 4, 2010/1731.3
Pertwee/Sept 3, 2010/4981.0
&#8942;        &#8942;            &#8942;
</pre>

    <p class="continue">
      It uses slashes as separators.
      There don't appear to be spaces in the site names,
      but the month names and day numbers vary in length.
      What's worse,
      the months are text, and the order is month-day-year rather than year-month-day.
    </p>

    <p>
      We could parse these files using basic string operations,
      but it would be difficult.
      A better approach is to use <a class="dfn" href="glossary.html#regular-expression">regular expressions</a>.
      A regular expression is just a pattern that can match a string.
      They are actually very common:
      when we say <code>*.txt</code> to a computer,
      we mean, "Match all of the filenames that end in <code>.txt</code>."
      The <code>*</code> is a regular expression:
      it matches any number of characters.
    </p>

    <p>
      The rest of this chapter will look at what regular expressions can do,
      and how we can use them to handle our data.
      A warning before we go any further, though:
      the notation for regular expressions is ugly, even by the standards of programming.
      Se're writing patterns to match strings,
      but we're writing those patterns <em>as</em> strings
      using only the symbols that are on the keyboard,
      instead of inventing new symbols the way mathematicians do.
      The good news is that regular expressions work more or less the same way
      in almost every programming language.
      We will present examples in Python,
      but the ideas and notation transfer directly to Perl, Java, MATLAB, C#, and Fortran.
    </p>

    <section id="s:basic">

      <h2>Simple Patterns</h2>

      <p>
        Let's start by reading data from two files,
        discarding the headers,
        and keeping the first few lines of each:
      </p>

<pre>
readings = []
for filename in ('data-1.txt', 'data-2.txt'):
  lines = open(filename, 'r').read().strip().split('\n')
  readings += lines[2:8]

for r in readings:
  print r
</pre>

      <p class="continue">
        This puts six lines from the first data file and six from the second
        into the list <code>readings</code>:
      </p>

<pre>
<span class="out">Baker 1 2009-11-17      1223.0
Baker 1 2010-06-24      1122.7
Baker 2 2009-07-24      2819.0
Baker 2 2010-08-25      2971.6
Baker 1 2011-01-05      1410.0
Baker 2 2010-09-04      4671.6
Davison/May 23, 2010/1724.7
Pertwee/May 24, 2010/2103.8
Davison/June 19, 2010/1731.9
Davison/July 6, 2010/2010.7
Pertwee/Aug 4, 2010/1731.3
Pertwee/Sept 3, 2010/4981.0</span>
</pre>

      <p class="continue">
        We will test our regular expressions against this data
        to see how well we are matching different record formats as we go along.
      </p>

      <p>
        Without regular expressions,
        we can select records that have the month "06" using <code>if '06' in record</code>:
      </p>

<pre>
for r in readings:
  if '06' in r:
    print r
<span class="out">Baker 1 2010-06-24      1122.7</span>
</pre>

      <p>
        If we want to select data for two months
        we have to use <code>if ('06' in record) or ('07' in record)</code>.
      </p>

<pre>
for r in readings:
  if ('06' in r) or ('07' in r):
    print r
<span class="out">Baker 1 2010-06-24      1122.7
Baker 2 2009-07-24      2819.0</span>
</pre>

      <p>
        But if we say <code>'05' in record</code>
        it can match against the day "05" as well as the month "05".
        We can try to write a more complicated test
        that only looks for the two-digit month in a particular place in the string,
        but let's try using a regular expression instead.
      </p>

      <p>
        We will work up to our solution in stages.
        We start by importing the regular expressions library,
        then examine each record in <code>readings</code>.
        If a regular expression search can find a match
        for the string <code>'06'</code> in the record,
        we print it out:
      </p>

<pre>
import re
for r in readings:
  if re.search('06', r):
    print r
<span class="out">Baker 1 2010-06-24      1122.7</span>
</pre>

      <p>
        So far, this does the same thing as <code>'06' in r</code>.
        But if we want to match <code>'06'</code> or <code>'07'</code>,
        regular expressions let us combine the two comparisons in a single expression:
      </p>

<pre>
import re
for r in readings:
  if re.search('06|07', r):
    print r
<span class="out">Baker 1 2010-06-24      1122.7
Baker 2 2009-07-24      2819.0</span>
</pre>

      <p>
        The first argument to <code>re.search</code> is the pattern we are searching for,
        written as a string.
        The second argument is the data we are searching in.
        It's easy to reverse these accidentally,
        i.e., to put the data first and the pattern second.
        This can be hard to track down, so please be careful.
      </p>

      <p>
        The vertical bar in the pattern means "or".
        It tells regular expression library that
        we want to match either the text on the left,
        or the text on the right.
        As we will see <a href="#s:mechanics">later</a>,
        the regular expression library can look for both patterns
        in a single operation.
      </p>

      <p>
        We are going to be throwing a lot of regular expressions against our data,
        so let's write a function that will tell us which records match a particular pattern.
        Our function <code>show_matches</code> takes a pattern and a list of strings as arguments.
        It prints out two stars as a marker
        if the pattern matches a string,
        and just indents with blanks if it does not:
      </p>

<pre>
def show_matches(pattern, strings):
  for s in strings:
    if re.search(pattern, s):
      print '**', s
    else:
      print '  ', s
</pre>

      <p>
        If we use this function to match <code>'06|07'</code> against the data we read in earlier,
        it prints stars beside the two records
        that have month <code>'06'</code> or month <code>'07'</code>:
      </p>

<pre>
show_matches('06|07', readings)
<span class="out">   Baker 1  2009-11-17  1223.0
** Baker 1  2010-06-24  1122.7
** Baker 2  2009-07-24  2819.0
   Baker 2  2010-08-25  2971.6
   Baker 1  2011-01-05  1410.0
   Baker 2  2010-09-04  4671.6
   Davison/May 23, 2010/1724.7
   Pertwee/May 24, 2010/2103.8
   Davison/June 19, 2010/1731.9
   Davison/July 6, 2010/2010.7
   Pertwee/Aug 4, 2010/1731.3
   Pertwee/Sept 3, 2010/4981.0</span>
</pre>

      <p>
        But if we change the pattern <code>'06|7'</code>
        (without a '0' in front of the '7'),
        the pattern seems to match a lot of things
        that don't have the month <code>'06'</code> or <code>'07'</code>:
      </p>

<pre>
show_matches('06|7', readings)
<span class="out">** Baker 1  2009-11-17  1223.0
** Baker 1  2010-06-24  1122.7
** Baker 2  2009-07-24  2819.0
** Baker 2  2010-08-25  2971.6
   Baker 1  2011-01-05  1410.0
** Baker 2  2010-09-04  4671.6
** Davison/May 23, 2010/1724.7
   Pertwee/May 24, 2010/2103.8
** Davison/June 19, 2010/1731.9
** Davison/July 6, 2010/2010.7
** Pertwee/Aug 4, 2010/1731.3
   Pertwee/Sept 3, 2010/4981.0</span>
</pre>

      <p>
        To understand why, think back to mathematics.
        The expression <em>ab+c</em> means "a times b plus c"
        because multiplication has higher precedence than addition.
        If we want to force the other meaning,
        we have to use parentheses and write <em>a(b+c)</em>.
      </p>

      <p>
        The same is true for regular expressions.
        Adjacency has higher precedence than "or",
        so the pattern <code>'06|7'</code> means,
        "Either <code>'06'</code> or the digit <code>'7'</code>".
        If we look back at our data, there are a lot of 7's in our file,
        and this pattern is matching all of them.
      </p>

      <p>
        If we want to match <code>'06'</code> or <code>'07'</code>
        without repeating the digit '0',
        we have to parenthesize it as <code>'0(6|7)'</code>.
        Having said that,
        most people probably find the expression <code>'06|07'</code> more readable anyway.
      </p>

      <p>
        Let's go back to our function and our data.
        If we use the pattern <code>'05'</code>,
        then as we said earlier,
        we will match records that have '05' as the day
        as well as those with '05' as the month.
        We can force our match to do the right thing by taking advantage of context.
        If the date is formatted as YYYY-MM-DD
        then there should be a dash <code>'-'</code> before and after the month,
        but only before the day.
        The pattern <code>'-05-'</code> should therefore only match a month of '05'.
        Sure enough,
        if we give this pattern to our function it doesn't match any records.
        This is the correct answer,
        since we don't have any readings in this sample of our data set for May.
      </p>

      <p>
        Matching is useful,
        but what we really want to do is extract the year, the month, and the day from our data
        so that we can reformat them.
        Parentheses can help here too:
        when a regular expression matches a piece of text,
        the library automatically remembers what matched against every parenthesized sub-expression.
      </p>

      <p>
        Here's a simple example:
      </p>

<pre>
match = re.search('(2009|2010|2011)',
                  'Baker 1\t2009-11-17\t1223.0')
print match.group(1)
</pre>

      <p class="continue">
        The first string is our pattern.
        It will match 2009, 2010, or 2011,
        and the parentheses around it will make the library remember
        which of those three strings was matched.
        The second string is just the first record from our data.
        (Remember, <code>'\t'</code> represents a tab.)
      </p>

      <p>
        When <code>re.search</code> is called,
        it returns <code>None</code> if it doesn't find a match,
        or a special <a class="dfn" href="glossary.html#match-object">match object</a> if it did.
        The expression <code>match.group</code> returns
        the text that matched the sub-expression inside the specified set of parentheses
        counting from the left.
        Since this pattern only has one set of parentheses,
        <code>match.group(1)</code> returns whatever matched what's inside them.
      </p>

      <p>
        The way sub-expressions are numbered sometimes trips people up.
        While Python normally counts from 0,
        the first match in a regular expression is extracted with <code>match.group(1)</code>,
        the second with 2,
        and so forth.
        The reason is that <code>match.group(0)</code> returns
        all of the text that the entire pattern matched.
      </p>

      <p>
        What if we want to match the month as well as the year?
        A regular expression to match legal months would be
        <code>'(01|02|03|04|05|06|07|08|09|10|11|12)'</code>.
        An expression to match days would be three times longer,
        which would be hard to type and (more importantly) hard to read.
      </p>

      <p>
        Instead, we can use the dot character <code>'.'</code> to match any single character.
        For example,
        the expression <code>'....-..-..'</code> matches exactly four characters,
        and <code>'....-..-..'</code> matches four characters,
        a dash,
        two more characters,
        another dash,
        and two more characters.
        If we put each set of dots in parentheses as <code>'(....)-(..)-(..)'</code>
        the three groups should record the year, month, and day
        each time there's a successful match.
      </p>

      <p>
        Let's test that out by calling <code>re.search</code>
        with the pattern we just described and the first record from our data:
      </p>

<pre>
match = re.search('(....)-(..)-(..)',
                  'Baker 1\t2009-11-17\t1223.0')
print match.group(1), match.group(2), match.group(3)
<span class="out">2009 11 17</span>
</pre>

      <p class="continue">
        When we print out the three groups,
        we get <code>'2009'</code>, <code>'11'</code>, and <code>'17'</code>,
        just as we wanted.
        Try doing <em>that</em> with substring searches&hellip;
      </p>

      <p>
        To recapitulate,
        leters and digits in a pattern match against themselves,
        so <code>'A'</code> matches an upper-case A.
        The vertical bar <code>'|'</code> means "or",
        a dot <code>'.'</code> matches any single character,
        and we use parentheses to enforce grouping and to remember things.
      </p>

      <p>
        Stepping back from the syntax,
        we have also seen that
        the right way to build a pattern is
        to start with something simple that matches part of the data we're working with,
        then add to it piece by piece.
        We test it against our data each time we make a change,
        but also test that it <em>doesn't</em> match things that it shouldn't,
        because false positive can be very hard to track down.
      </p>

    </section>

    <section id="s:operators">

      <h2>Operators</h2>

      <p>
        Let's go back to those measurements.
        Notebook #1 has the site, date, and background evil level
        with single tabs as separators.
        Some of the site names have spaces,
        and the dates are in the international standard format YYYY-MM-DD.
        However,
        the fields in Notebook #2 are separated by slashes,
        and use months' names instead of numbers.
        What's more,
        some of the month names are three characters long,
        while others are four,
        and the days are either one or two digits.
      </p>

      <p>
        Before looking at how to use regular expressions to extract data from Notebook #2,
        let's see how we would do it with simple string operations.
        If our records look like <code>'Davison/May 22, 2010/1721.3'</code>,
        we can split on slashes to separate the site, date, and reading.
        We could then split the middle field on spaces to get the month, day, and year,
        and then remove the comma from the day if it is present
        (because some of our readings don't have a comma after the day).
      </p>

      <p>
        This is a <a class="dfn" href="glossary.html#procedural-programming">procedural</a> way to solve the problem:
        we tell the computer what procedure to follow step by step to get an answer.
        In contrast, regular expressions are <a class="dfn" href="glossary.html#declarative-programming">declarative</a>:
        we declare, "This is what we want," and let the computer figure out how to calculate it.
      </p>

      <p>
        Our first attempt to parse this data will rely on the <code>*</code> operator.
        It is a <a class="dfn" href="glossary.html#postfix-operator">postfix</a> operator,
        just like the 2 in x<sup>2</sup>,
        and means, "Zero or more repetitions of the pattern that comes before it".
        For example,
        <code>'a*'</code> matches zero or more 'a' characters,
        while <code>'.*'</code> matches any sequence of characters
        (including the empty string)
        because <code>'.'</code> matches anything and <code>'*'</code> repeats.
        Note that the characters matched by <code>'.*'</code> do <em>not</em> all have to be the same:
        the rule is not, "Match a character against the dot, then repeat that match zero or more times,"
        but rather, "Zero or more times, match any character."
      </p>

      <p>
        Here's a test of a simple pattern using <code>'.*'</code>:
      </p>

<pre>
match = re.search('(.*)/(.*)/(.*)',
                  'Davison/May 22, 2010/1721.3')
print match.group(1)
print match.group(2)
print match.group(3)
</pre>

      <p class="continue">
        In order for the entire pattern to match,
        the slashes '/' have to line up exactly,
        because '/' only matches against itself.
        That constraint ought to make the three uses of <code>'.*'</code> match
        the site name, date, and reading.
        Sure enough, the output is:
      </p>

<pre>
<span class="out">Davison
May 22, 2010
1271.3</span>
</pre>

      <p>
        Unfortunately, we've been over-generous.
        Let's put brackets around each group in our output to make matches easier to see,
        then apply this pattern to the string <code>'//'</code>:
      </p>

<pre>
match = re.search('(.*)/(.*)/(.*)',
                  '//')
print '[' + match.group(1) + ']'
print '[' + match.group(2) + ']'
print '[' + match.group(3) + ']'
<span class="out">[]
[]
[]</span>
</pre>

      <p>
        We don't want our pattern to match invalid records like this
        (remember, "Fail early, fail often").
        However,
        <code>'.*'</code> can match the empty string because it is zero occurrences of a character.
      </p>

      <p>
        Let's try a variation that uses <code>+</code> instead of <code>*</code>.
        <code>+</code> is also a postfix operator, but it means "one or more",
        i.e., it has to match at least one occurrence of the pattern that comes before it.
      </p>

<pre>
match = re.search('(.+)/(.+)/(.+)',
                  '//')
print match
<span class="out">None</span>
</pre>

      <p>
        As we can see, the pattern <code>(.+)/(.+)/(.+)</code>
        <em>doesn't</em> match a string containing only slashes
        because there aren't characters before, between, or after the slashes.
        And if we go back and check it against valid data,
        it seems to do the right thing:
      </p>

<pre>
print re.search('(.+)/(.+)/(.+)',
                'Davison/May 22, 2010/1721.3')
print '[' + m.group(1) + ']'
print '[' + m.group(2) + ']'
print '[' + m.group(3) + ']'
<span class="out">[Davison]
[May 22, 2010]
[1721.3]</span>
</pre>

      <p>
        We're going to match a lot of patterns against a lot of strings,
        so let's write a function to apply a pattern to a piece of text,
        report whether it matches or not,
        and print out the match groups if it does:
      </p>

<pre>
def show_groups(pattern, text):
  m = re.search(pattern, text)
  if m is None:
    print 'NO MATCH'
    return
  for i in range(1, 1 + len(m.groups())):
    print '%2d: %s' % (i, m.group(i))
</pre>

      <p class="continue">
        We'll test our function against the two records we were just using:
      </p>

<pre>
show_groups('(.+)/(.+)/(.+)',
            'Davison/May 22, 2010/1721.3')
<span class="out">1: Davison
2: May 22, 2010
3: 1721.3</span>
</pre>

<pre>
show_groups('(.+)/(.+)/(.+)',
            '//)
<span class="out">NO MATCH</span>
</pre>

      <p>
        All right:
        if we're using regular expressions to extract the site, date, and reading,
        why not add more groups to break up the date while we're at it?
      </p>

<pre>
show_groups('(.+)/(.+) (.+), (.+)/(.+)',
            'Davison/May 22, 2010/1721.3')
<span class="out">1: Davison
2: May
3: 22
4: 2010
5: 1721.3</span>
</pre>

      <p>
        But wait a second: why doesn't this work?
      </p>

<pre>
show_groups('(.+)/(.+) (.+), (.+)/(.+)',
            'Davison/May 22 2010/1721.3')
<span class="out">None</span>
</pre>

      <p>
        The problem is that the string we're trying to match
        doesn't have a comma after the day.
        There is one in the pattern, so matching fails.
      </p>

      <p>
        We could try to fix this by putting <code>'*'</code> after the comma in the pattern,
        but that would match any number of consecutive commas in the data,
        which we don't want either.
        Instead, let's use a question mark <code>'?'</code>,
        which is yet another postfix operator meaning, "0 or 1 of whatever comes before it".
        Another way of saying this is that the pattern that comes before the question mark is optional.
        If we try our tests again,
        we get the right answer in both cases:
      </p>

<pre>
# with comma in data
show_groups('(.+)/(.+) (.+),? (.+)/(.+)',
            'Davison/May 22, 2010/1721.3')
<span class="out">1: Davison
2: May
3: 22
4: 2010
5: 1721.3</span>
</pre>

<pre>
# without comma in data
show_groups('(.+)/(.+) (.+),? (.+)/(.+)',
            'Davison/May 22 2010/1721.3')
<span class="out">1: Davison
2: May
3: 22
4: 2010
5: 1721.3</span>
</pre>

      <p>
        Let's tighten up our pattern a little bit more.
        We <em>don't</em> want to match this record:
      </p>

<pre>
Davison/May 22, 201/1721.3
</pre>

      <p class="continue">
        because somebody mis-typed the year, entering three digits instead of four.
        (Either that,
        or whoever took this reading was also using the physics department's time machine.)
        We could use four dots in a row to force the pattern to match exactly four digits:
      </p>

<pre>
(.+)/(.+) (.+),? (....)/(.+)
</pre>

      <p class="continue">
        but this won't win any awards for readability.
        Instead, let's put the digit <code>4</code> in curly braces <code>{}</code> after the dot:
      </p>

<pre>
(.+)/(.+) (.+),? (.{4})/(.+)
</pre>

      <p>
        In a regular expression,
        curly braces with a number between them means,
        "Match the pattern exactly this many times".
        Since <code>.</code> matches any character,
        <code>.{4}</code> means "match any four characters".
      </p>

      <p>
        Let's do a few more tests.
        Here are some records in which the dates are either correct or mangled:
      </p>

<pre>
tests = (
    'Davison/May , 2010/1721.3',
    'Davison/May 2, 2010/1721.3',
    'Davison/May 22, 2010/1721.3',
    'Davison/May 222, 2010/1721.3',
    'Davison/May 2, 201/1721.3',
    'Davison/ 22, 2010/1721.3',
    '/May 22, 2010/1721.3',
    'Davison/May 22, 2010/'
)
</pre>

      <p class="continue">
        And here's a pattern that should match all the records that are correct,
        but should fail to match all the records that have been mangled:
      </p>

<pre>
pattern = '(.+)/(.+) (.{1,2}),? (.{4})/(.+)'
</pre>

      <p class="continue">
        We are expecting four digits for the year,
        and we are allowing 1 or 2 digits for the day,
        since the expression <code>{M,N}</code> matches a pattern from M to N times.
      </p>

      <p>
        When we run this pattern against our test data, three records match:
      </p>

<pre>
show_matches(pattern, tests)
<span class="out">** Davison/May , 2010/1721.3
** Davison/May 2, 2010/1721.3
** Davison/May 22, 2010/1721.3
   Davison/May 222, 2010/1721.3
   Davison/May 2, 201/1721.3
   Davison/ 22, 2010/1721.3
   /May 22, 2010/1721.3
   Davison/May 22, 2010/</span>
</pre>

      <p>
        The second and third matches make sense:
        'May 2' and 'May 22' are both valid.
        But why does 'May' with no date at all match this pattern?
        Let's look at that test case more closely:
      </p>

<pre>
show_groups('(.+)/(.+) (.{1,2}),? (.{4})/(.+)',
            'Davison/May , 2010/1721.3')
<span class="out">1: Davison
2: May
3: ,
4: 2010
5: 1721.3</span>
</pre>

      <p class="continue">
        The groups are 'Davison' (that looks right),
        'May' (ditto),
        a ',' on its own (which is clearly wrong),
        and then the right year and the right reading.
      </p>

      <p>
        Here's what's happened.
        The space ' ' after 'May' matches the space ' ' in the pattern.
        The expression "1 or 2 occurrences of any character"
        matches the comma ',' because ',' is a character and it occurs once.
        The expression ',
        ' is then not matched against anything, because it's allowed to match zero characters.
        '?' means "optional",
        and in this case,
        the regular expression pattern matcher is deciding not to match it against anything,
        because that's the only way to get the whole pattern to match the whole string.
        After that, the second space matches the second space in our data.
        This is obviously not what we want,
        so let's modify our pattern again:
      </p>

<pre>
show_groups('(.+)/(.+) ([0-9]{1,2}),? (.{4})/(.+)',
            'Davison/May , 2010/1721.3')
<span class="out">None</span>
</pre>

<pre>
show_groups('(.+)/(.+) ([0-9]{1,2}),? (.{4})/(.+)',
            'Davison/May 22, 2010/1721.3')
<span class="out">1: Davison
2: May
3: 22
4: 2010
5: 1721.3</span>
</pre>

      <p>
        The pattern <code>'(.+)/(.+) ([0-9]{1,2}),? (.{4})/(.+)'</code>
        does the right thing for the case where there is no day,
        and also for the case where there is one.
        It works because
        we have used <code>[0-9]</code> instead of <code>'.'</code>.
      </p>

      <p>
        In regular expressions,
        square brackets <code>[]</code> are used to create sets of characters.
        For example, the expression <code>[aeiou]</code> matches exactly one vowel,
        i.e.,
        exactly one occurrence of any character in the set.
        We can either write these sets out character by character,
        as we've done with vowels,
        or as "first character '-' last character"
        if the characters are in a contiguous range.
        This is why <code>'[0-9]'</code> matches exactly one digit.
      </p>

      <p>
        Here's our completed pattern:
      </p>

<pre>
(.+)/([A-Z][a-z]+) ([0-9]{1,2}),? ([0-9]{4})/(.+)'
</pre>

      <p class="continue">
        We have added one more feature to it:
        the name of the month has to begin with an upper-case letter,
        i.e., a character in the set <code>[A-Z]</code>,
        which must followed by one or more lower-case characters in the set <code>[a-z]</code>.
      </p>

      <p>
        This pattern still isn't perfect:
        the day is one or more occurrences of the digits 0 through 9,
        which will allow "days" like '0', '00', and '99'.
        It's easiest to check for mistakes like this after we convert the day to an integer,
        since trying to handle things like leap years with regular expressions
        would be like trying to build a house with a Swiss army knife.
      </p>

      <p>
        Finally,
        the year in our final pattern is exactly four digits,
        so it's the set of characters <code>[0-9]</code> repeated four times.
        Again, we will check for invalid values like '0000' after we convert to integer.
      </p>

      <p>
        Using the tools we've seen so far,
        we can write a simple function that will extract the date
        from either of the notebooks we have seen so far
        and return the year, the month, and the day as strings:
      </p>

<pre>
def get_date(record):
  '''Return (Y, M, D) as strings, or None.'''

  # 2010-01-01
  m = re.search('([0-9]{4})-([0-9]{2})-([0-9]{2})',
                record)
  if m:
    return m.group(1), m.group(2), m.group(3)

  # Jan 1, 2010 (comma optional, day may be 1 or 2 digits)
  m = re.search('/([A-Z][a-z]+) ([0-9]{1,2}),? ([0-9]{4})/',
                record)
  if m:
    return m.group(3), m.group(1), m.group(2)

  return None
</pre>

      <p class="continue">
        We start by testing whether the record contains an ISO-formatted date YYYY-MM-DD.
        If it does, then we return those three fields right away.
        Otherwise, we test the record against a second pattern
        to see if we can find the name of a month,
        one or two digits for the day,
        and four digits for the year
        with slashes between the fields.
        If so, we return what we find, permuting the order to year, month, day.
        Finally,
        if neither pattern matched we return <code>None</code> to signal that
        we couldn't find anything in the data.
      </p>

      <p>
        This is probably the most common way to use regular expressions:
        rather than trying to combine everything into one enormous pattern,
        we have one pattern for each valid case.
        We test of those cases in turn;
        if it matches, we return what we found,
        and if it doesn't,
        we move on to the next pattern.
        Writing our code this way make it easier to understand
        than using a single monster pattern,
        and easier to extend if we have to handle more data formats.
      </p>

    </section>

    <section id="s:mechanics">

      <h2>Under the Hood</h2>

      <p>
        The regular expression <code>'([A-Z][a-z]+) ([0-9]{1,2}),? ([0-9]{4})'</code>
        matches a single upper-case character and one or more lower-case characters,
        a space,
        one or two digits,
        an optional comma,
        another space,
        and exactly four digits.
        That is pretty complex,
        and knowing a little about how the computer actually does it
        will help us debug regular expressions when they don't do what we want.
      </p>

      <p>
        Regular expressions are implemented using
        <a class="dfn" href="glossary.html#finite-state-machine">finite state machines</a>.
        Here's a very simple FSM that matches exactly one lower case 'a':
      </p>

      <img src="../img/regexp/fsm-single-lower-case-a.png" alt="FSM matching a single lower case 'a'" />

      <p class="continue">
        Matching starts with the incoming arrow on the left,
        which takes us to the first state in our finite state machine.
        The only way to get from there to the second state is to match
        the 'a' on the arc between states 1 and 2.
        The dot in the middle of the second state means that it's an end state.
        We must be in one of these states at the end of our match in order for the match to be valid.
      </p>

      <p>
        Now that we have an FSM that matches the very simple regular expression <code>'a'</code>,
        let's see if we can do something a little more interesting.
        Here's a finite state machine that matches one or more occurrences of the letter 'a':
      </p>

      <img src="../img/regexp/fsm-one-or-more-a.png" alt="FSM matching one or more letter 'a'" class="floatright" />

      <p class="continue">
        The first arc labelled 'a' gets us from the initial state to an end state,
        but we don't have to stop there:
        the curved arc at the top allows us to match another 'a',
        and brings us back to the same state.
        We can then match another 'a', and another, and so on indefinitely.
        (Note that we don't have to stop in the end state the first time we reach it:
        we just have to be in an end state when we run out of input.)
        The pattern this FSM matches is <code>'a+'</code>,
        since one 'a' followed by zero or more others is the same as
        one or more occurences of 'a'.
      </p>

      <p>
        Here's another FSM that matches against the letter 'a' or nothing:
      </p>

      <img src="../img/regexp/fsm-one-a-or-nothing.png" alt="FSM matching one letter 'a' or nothing" class="floatright" />

      <p class="continue">
        The top arc isn't marked, so that transition is free:
        we can go from the first state to the second state without consuming any of our input.
        This is "a or nothing", which is the same as <code>'a?'</code>,
        i.e., an optional character 'a'.
      </p>

      <p>
        This regular expression looks like the one that matches 'a' one or more times,
        except there is an extra arc to get us from the first state to the second
        without consuming any input:
      </p>

      <img src="../img/regexp/fsm-zero-or-more-a.png" alt="FSM matching zero or more letter 'a'" class="floatleft" />

      <p class="continue">
        It is therefore equivalent to the pattern <code>'a*'</code>,
        i.e.,
        it matches nothing at all (taking that free transition from the first state to the second)
        or one or more occurrences of 'a'.
        We can simplify this considerably like this:
      </p>

      <img src="../img/regexp/fsm-simpler-zero-or-more-a.png" alt="FSM matching zero or more letter 'a'" class="floatright" />

      <p>
        The simple FSMs we have seen so far are enough to implement
        most of the regular expressions in the previous sections.
        For example, look at this finite state machine:
      </p>

      <img src="../img/regexp/fsm-complex.png" alt="A more complex FSM" />

      <p class="continue">
        We can either take the top route or the bottom.
        The top route is <code>a+</code>;
        the bottom route is a 'b', followed by either a 'c' or a 'd',
        so this whole thing is equivalent to
        the regular expression <code>'a+|(b(c|d))'</code>.
        An input string that matches any of these paths will leave us in that final end state.
      </p>

      <p>
        The most important thing about finite state machines is that
        the action they take at a node depends on only
        the arcs out of that node and the characters in the target data.
        Finite state machines do <em>not</em> remember how they got to a particular node:
        decision-making is always purely local.
      </p>

      <p>
        This means that there are many patterns that regular expressions <em>cannot</em> match.
        For example,
        it is impossible to write a regular expression to check if nested parentheses match.
        If we want to see whether '(((&hellip;)))' is balanced,
        we need some kind of memory,
        or at least a counter,
        and there isn't any in a finite state machine.
      </p>

      <p>
        Similarly, if we want to check whether a word contains each vowel only once,
        the only way to do it is to write a regular expression with 120 clauses,
        that checks for each possible permutation of 'aeiou' explicitly.
        We cannot write a regular expression that matches an arbitrary vowel,
        and then subtracts that vowel from the set of vowels yet to be matched,
        because once again,
        that would require some kind of memory,
        and finite state machines don't have any.
      </p>

      <p>
        Despite this limitation, regular expressions are tremendously useful.
        The first reason is that they are really fast.
        After the computer does some pre-calculation
        (essentially, once it turns the regular expression into a finite state machine)
        a regular expression can be matched against input by looking at each input character only once.
        That means that the time required to find patterns with regular expressions
        grows in proportion to the size of the data.
        The time required for most other pattern-matching techniques grows much faster,
        so if regular expressions can do the job,
        they are almost always the most efficient option available.
      </p>

      <p>
        Another reason for using regular expressions is that
        they are more readable than other alternatives.
        You might not think so looking at the examples so far,
        but imagine writing lines of code to match that same patterns.
        Nobody would claim that regular expressions are easy to understand,
        but they're a lot easier than two dozen lines of substring operations.
      </p>

    </section>

    <section id="s:patterns">

      <h2>More Patterns</h2>

      <p>
        Now that we know how regular expressions work,
        let's have a look at Notebook #3:
      </p>

<pre>
Date Site Evil(mvad)
May 29 2010 (Hartnell) 1029.3
May 30 2010 (Hartnell) 1119.2
June 1 2010 (Hartnell) 1319.4
May 29 2010 (Troughton) 1419.3
May 30 2010 (Troughton) 1420.0
June 1 2010 (Troughton) 1419.8
&#8942;            &#8942;           &#8942;
</pre>

      <p class="continue">
        It has the date as three fields, the site name in parentheses, and then the reading.
        We know how to parse dates in this format,
        and the fields are separated by spaces,
        but how do we match those parentheses?
        The parentheses we have seen in regular expressions so far haven't matched characters:
        they have created groups.
      </p>

      <p>
        The way we solve this problem&mdash;i.e.,
        the way we match a literal left parenthesis '(' or right parenthesis ')'&mdash;is
        to put a backslash in front of it.
        This is another example of an <a class="dfn" href="glossary.html#escape-sequence">escape sequence</a>:
        just as we use the two-character sequence <code>'\t'</code> in a string
        to represent a literal tab character,
        we use the two-character sequence <code>'\('</code> or <code>'\)'</code> in a regular expression
        to match the literal character '(' or ')'.
      </p>

      <p>
        To get that backslash '\' into the string, though, we have to escape <em>it</em> by doubling it up.
        This has nothing to do with regular expressions:
        it is Python's rule for putting backslashes in strings.
        The string representation of the regular expression that matches an opening parenthesis is
        therefore <code>'\\('</code>.
        This can be confusing, so let's take a look at the various layers involved.
      </p>

      <p>
        Our program text&mdash;i.e., what's stored in our <code>.py</code> file&mdash;looks like this:
      </p>

<pre>
# find '()' in text
m = re.search('\\(\\)', text)
&#8942;    &#8942;    &#8942;
</pre>

      <p class="continue">
        The file has two backslashes, an open parenthesis, two backslashes, and a close parenthesis inside quotes:
      </p>

      <table border="1" cellpadding="3">
        <tr>
          <td>\</td>
          <td>\</td>
          <td>(</td>
          <td>\</td>
          <td>\</td>
          <td>)</td>
        </tr>
      </table>

      <p class="continue">
        When Python reads that file in,
        it turns the two-character sequence '\\' into a single '\' character in the string in memory.
        This is the first round of escaping.
      </p>

      <table border="1" cellpadding="3">
        <tr>
          <td>\</td>
          <td>(</td>
          <td>\</td>
          <td>)</td>
        </tr>
      </table>

      <p>
        When we hand that string '\(\)' to the regular expression library,
        it takes the two-character sequence '\('
        and turns it into an arc in the finite state machine that matches a literal parenthesis:
      </p>

      <img src="../img/regexp/fsm-match-parentheses.png" alt="More complex FSM" />

      <p>
        Turning this over,
        if we want a literal parenthesis to be matched,
        we have to give the regular expression library '\('.
        If we want to put '\(' in a string,
        we have to write it in our <code>.py</code> file as '\\('.
      </p>

      <p>
        With that out of the way, let's go back to Notebook #3.
        The regular expression that will extract the five fields from each record is
        <code>'([A-Z][a-z]+)&nbsp;([0-9]{1,2})&nbsp;([0-9]{4})&nbsp;\\((.+)\\)&nbsp;(.+)'</code>,
        which is:
      </p>

      <ul>
        <li>
          a word beginning with an upper-case character followed by one or more lower-case characters,
        </li>
        <li>
          a space,
        </li>
        <li>
          one or two digits,
        </li>
        <li>
          another space,
        </li>
        <li>
          four digits,
        </li>
        <li>
          another space,
        </li>
        <li>
          some stuff involving backslashes and parentheses,
        </li>
        <li>
          another space,
        </li>
        <li>
          and then one or more characters making up the reading.
        </li>
      </ul>

      <p>
        If we take a closer look at that "stuff",
        <code>'\\('</code> and <code>'\\)'</code> are how we write the regular expressions
        that match a literal open parenthesis '(' or close parenthesis ')' character in our data.
        The two inner parentheses that don't have backslashes in front of them create a group,
        but don't match any literal characters.
        We create that group so that we can save the results of the match (in this case, the name of the site).
      </p>

      <p>
        Now that we know how to work with backslahes in regular expressions,
        we can take a look at character sets that come up frequently enough to deserve their own abbreviations.
        If we use <code>'\d'</code> in a regular expression it matches the digits 0 through 9.
        If we use <code>'\s'</code>, it matches the whitespace characters,
        space, tab, carriage return, and newline.
        <code>'\w'</code> matches word characters;
        it's equivalent to the set <code>'[A-Za-z0-9_]'</code>
        of upper-case letters, lower-case letters, digits, and the underscore.
        (It's actually the set of characters that can appear in a variable name in a programming language like C or Python.)
        Again, in order to write one of these regular expressions as a string in Python, we have to double the backslashes.
      </p>

      <p>
        Now that we've seen these character sets,
        we can take a look at an example of really bad design.
        The regular expression <code>'\S'</code> means "non-space characters",
        i.e., everything that <em>isn't</em> a space, tab, carriage return, or newline.
        That might seem to contradict what we said in the previous paragraph,
        but if we look closely,
        that's an upper-case 'S', not a lower-case 's'.
      </p>

      <p>
        Similarly, and equally unfortunately,
        <code>'\W'</code> means "non-word characters" provided it's an upper-case 'W'.
        Upper- and lower-case 'S' and 'W' look very similar,
        particularly when there aren't other characters right next to them to give context.
        This means that these sequences are very easy to mis-type and mis-read.
        Everyone eventually uses an upper-case 'S' when they meant to use a lower-case 's' or vice versa,
        and then wastes a few hours trying to track it down.
        So please, if you're ever designing a library that's likely to be widely used,
        try to choose a notation that doesn't make mistakes this easy.
      </p>

      <p>
        Along with the abbreviations for character sets,
        the regular expression library recognizes a few shortcuts for things that aren't actual characters.
        For example, if we put a circumflex <code>'^'</code> at the start of a pattern,
        it matches the beginning of the input text.
        (Note that there's no backslash in front of it.)
        This means that the pattern <code>'^mask'</code> will match the text <code>'mask size'</code>,
        because the letters 'mask' come at the start of the string,
        but will <em>not</em> match the word <code>'unmask'</code>.
        Going to the other end,
        if dollar sign <code>'$'</code> is the last character in the pattern,
        it matches the end of the line rather than a literal '$',
        so 'temp$' will match the string 'high-temp',
        but not the string 'temperature'.
      </p>

      <div class="box">

        <p class="boxtitle">
          Regular Expressions and Newlines
        </p>

        <p>
          The full rule is slightly more complicated.
          By default, regular expressions act as if newline characters were the ends of records.
          For example, the <code>'.'</code> pattern matches everything <em>except</em> a newline.
          This normally doesn't matter,
          since most I/O routines return one line of text at a time,
          but if we read a whole file into a single string,
          then try to match across line boundaries,
          we may not get the behavior we expect.
          We can use the <code>MULTILINE</code> option in our matches to prevent this;
          please see the regular expression documentation for details.
        </p>

      </div>

      <p>
        A third shortcut that's often useful is <code>'\b'</code>, often called "break".
        It doesn't match any characters;
        instead, it matches the boundary between word and non-word characters
        (where "word" means upper and lower case characters, digits, and the underscore).
        For example,
        the regular expression <code>'\bage\b'</code> will match the string <code>'the age of'</code>
        because there's a non-word character right before the 'a' and another non-word character right after the 'e'.
        That same pattern will not match the word <code>'phage'</code>
        because there isn't a transition from non-word to word characters, or vice versa, right before the 'a'.
        And remember:
        to get that regular expression int our program,
        we have to escape the backslashes using <code>'\\bage\\b'</code>.
      </p>

    </section>

    <section id="s:declarative">

      <h2>One Last Wrinkle</h2>

      <p>
        Let's have one last look at the function we wrote to extract data from lab notebooks:
      </p>

<pre>
def get_date(record):
  '''Return (Y, M, D) as strings, or None.'''

  # 2010-01-01
  m = re.search('([0-9]{4})-([0-9]{2})-([0-9]{2})',
                record)
  if m:
    return m.group(1), m.group(2), m.group(3)

  # Jan 1, 2010 (comma optional, day may be 1 or 2 digits)
  m = re.search('/([A-Z][a-z]+) ([0-9]{1,2}),? ([0-9]{4})/',
                record)
  if m:
    return m.group(3), m.group(1), m.group(2)

  return None
</pre>

      <p>
        We can make it easier to add new patterns to this function
        by making it more declarative.
        The trick is to combine the regular expressions
        and the IDs of the groups we want to return:
      </p>

<pre>
def get_fields(record):
  '''Return (Y, M, D, site, reading) or None.'''

  patterns = [
    ['(.+)\t([0-9]{4})-([0-9]{2})-([0-9]{2})\t(.+)',      2, 3, 4, 1, 5],
    ['(.+)/([A-Z][a-z]+) ([0-9]{1,2}),? ([0-9]{4})/(.+)', 4, 2, 3, 1, 5]
  ]
  for pattern, year, month, day, site, reading in patterns:
    m = re.search(pattern, record)
    if m:
      return m.group(year), m.group(month), m.group(day),
             m.group(site), m.group(reading)

  return None
</pre>

      <p>
        Each entry in the list <code>patterns</code> has two parts:
        a regular expression,
        and then the indices of the group that will contain the year, month, day, site, and reading
        if that pattern matches.
        The loop tries the regular expressions in <code>patterns</code> one by one.
        As soon as a pattern matches it returns the matched groups,
        permuting them according to the indices so that the data always comes back in the same order.
        To handle the format in Notebook #3,
        we just add one line to this table:
      </p>

<pre>
    ['([A-Z][a-z]+) ([0-9]{1,2}) ([0-9]{4}) \\((.+)\\) (.+)', 3, 1, 2, 4, 5]
</pre>

      <p>
        Using a table might not seem like much of an improvement over
        the "match, extract, and return" style we have been using so far.
        However,
        the table-based approach has one major advantage:
        it signals to the reader that all the patterns are being handled the same way.
        It's all too easy for programmers to tweak the branches of a "match, extract, and return" function
        so that each possibility is handled in a slightly different way.
        This makes it very hard for readers to understand what's going on,
        and equally hard for the next programmer in line to debug or extend the code.
        The more declarative the code is,
        the more confidence readers can have that
        there really is only one thing for them to understand.
      </p>

    </section>

    <section id="s:tools">

      <h2>More Tools</h2>

      <p>
        To end our exploration of regular expressions,
        let's work through a moderately complex problem
        and introduce a few more tools in the regular expression library.
        Our starting point is an archive of several thousand papers and theses written in LaTeX,
        a text-based document formatting program.
        LaTeX documents use labels to refer to items in a shared bibliography.
        Our job is to find out how often citations appear together,
        i.e., how often paper X is cited in the same document as paper Y.
        To answer this question we need to extract the set of citation labels from each document.
      </p>

      <p>
        Let's have a closer look at our input:
      </p>

<pre>
Granger's work on graphs \cite{dd-gr2007,gr2009},
particularly ones obeying Snape's Inequality
\cite{ snape87 } (but see \cite{quirrell89}),
has opened up new lines of research.  However,
studies at Unseen University \cite{stibbons2002,
stibbons2008} highlight several dangers.
&#8942;    &#8942;    &#8942;
</pre>

      <p class="continue">
        Citations in LaTeX are written using <code>\cite{&hellip;}</code>,
        with cross-reference labels in the curly braces.
        A single citation can include two or more labels separated by commas.
        There may be white space before or after labels
        or line breaks where a citation is split across two lines,
        and there can be multiple citations per line.
      </p>

      <p>
        Our first idea is to use a group to capture everything inside the curly braces following the word 'cite':
      </p>

<pre>
m = re.search('cite{(.+)}', 'a \\cite{X} b')
print m.groups()
</pre>
<pre class="out">
('X',)
</pre>

      <p class="continue">
        It seems to work in one simple case,
        but what if there are multiple citations on a single line?
      </p>

<pre>
m = re.search('cite{(.+)}', 'a \\cite{X} b \\cite{Y} c')
print m.groups()
<span class="out">('X} b \\cite{Y',)</span>
</pre>

      <p class="continue">
        It looks like we're capturing the text <em>between</em> the citations.
        The reason is that regular expression matching is <a class="dfn" href="glossary.html#greedy-matching">greedy</a>:
        it matches as much text as it can,
        and the '.' in <code>'.+'</code> will match all the characters from the first curly brace to the last one,
        including the intervening citations and curly braces.
      </p>

      <p>
        The diagnosis of our problem suggests its solution:
        let's have the regular expression match everything <em>except</em> a closing curly brace.
        This is easy to do:
        if the first character of a set in square brackets is the circumflex '^',
        then the set is negated,
        i.e., it matches everything <em>except</em> the characters in the set.
        The expression <code>[^}]</code> therefore matches every character except a closing curly brace.
        Let's try it out:
      </p>

<pre>
m = re.search('cite{([^}]+)}', 'a \\cite{X} b')
print m.groups()
<span class="out">('X,)</span>
</pre>

      <p>
        This works for a single citation:
        all we've done is change '.' to the negated set.
        What about multiple citations on a single line?
      </p>

<pre>
m = re.search('cite{([^}]+)}', 'a \\cite{X} b \\cite{Y} c')
print m.groups()
<span class="out">('X,)</span>
</pre>

      <p class="continue">
        It's not gobbling up text we don't want it to, but it's only capturing the first citation.
        Somehow, we need to extract all matches, not just the first.
      </p>

      <p>
        The regular expression library has a function to do exactly this:
        if we use <code>re.findall</code> instead of <code>re.search</code>,
        it will give us back a list of all the substrings that matched our pattern.
        Remember, whatever your problem is,
        someone has probably run into it before,
        and there's probably something in the library to help you.
        Knowing what's in the library is as important to a programmer as knowing what's in the literature is to a scientist.
        The bad news is,
        it's usually hard to find things in libraries or their documentation
        unless you already know enough about your problem to know what keywords to search for.
      </p>

      <p>
        Let's give <code>findall</code> a try:
      </p>

<pre>
print re.findall('cite{([^}]+)}', 'a \\cite{X} b \\cite{Y} c')
<span class="out">['X', 'Y']</span>
</pre>

      <p class="continue">
        It seems to produce the right output&mdash;not bad for a 7-character change.
        What about spaces in citations?
      </p>

<pre>
print re.search('cite{([^}]+)}', 'a \\cite{ X} b \\cite{Y } c').groups()
<span class="out">[' X', 'Y ']</span>
</pre>

      <p>
        The good news is, nothing breaks.
        The bad news is, the spaces are saved by <code>findall</code>, which isn't really what we want.
        We could tidy this up after the fact using <code>string.strip</code>,
        but let's modify the pattern instead:
      </p>

<pre>
print re.findall('cite{\\s*([^}]+)\\s*}', 'a \\cite{ X} b \\cite{Y } c')
<span class="out">['X', 'Y ']</span>
</pre>

      <p>
        If you recall,
        <code>'\s'</code> is an abbrevation for the set of whitespace characters,
        so these uses of <code>'\s*'</code> match zero or more spaces immediately after the opening curly brace,
        or immediately before the closing one
        (and as always we have to write <code>'\\s'</code>
        to get the backslash into the Python string).
        However, the space after the 'Y' is still being returned in the matched text.
      </p>

      <p>
        Once again,
        the problem is that regular expressions are greedy:
        the space after the 'Y' isn't a closing curly brace,
        so it's matched by the negated character set, and included in the returned string.
        The <code>'\s*'</code> that's supposed to match the trailing space
        is then matched against zero characters instead of one.
        It's not what we want, but it's legal.
      </p>

      <p>
        Let's force our match to line up with the break from word to non-word characters using <code>'\b'</code>:
      </p>

<pre>
print re.findall('cite{\\s*\\b([^}]+)\\b\\s*}', 'a \\cite{ X} b \\cite{Y } c')
<span class="out">['X', 'Y']</span>
</pre>

      <p class="continue">
        It works!
        <span class="fixme">check this last example: in the PowerPoint, there's still a space before the 'X'</span>
        The change is to put <code>'\b'</code> after the first unwanted spaces,
        and before the last ones.
        Since the curly braces around the citation labels are also non-word characters,
        the pattern matches even if there aren't any opening or trailing spaces.
      </p>

      <p>
        The last hurdle is to handle multiple labels inside a single pair of curly braces.
        The pattern we've built so far doesn't explode when there are two or more labels,
        and it even handles spaces after the commas,
        but it returns all those labels as a single lump of text:
      </p>

<pre>
print re.findall('cite{\\s*\\b([^}]+)\\b\\s*}', '\\cite{X,Y} ')
<span class="out">['X,Y']</span>
</pre>

<pre>
print re.findall('cite{\\s*\\b([^}]+)\\b\\s*}', '\\cite{X, Y, Z} ')
<span class="out">['X, Y, Z']</span>
</pre>

      <p>
        We actually could write a pattern that would break everything up on commas,
        but it would need some very advanced features of the regular expression library.
        Instead, let's use another basic function, <code>re.split</code>, to separate multiple labels.
        <code>re.split</code> does the same thing as <code>string.split</code>,
        but unlike its simpler cousin,
        it breaks things up everywhere that a pattern matches.
      </p>

      <p>
        The best way to show how it works is to write the function we originally set out to create.
        Let's start with a skeleton that includes some test data,
        a function that does nothing (but doesn't just fail),
        and a couple of lines that call that function and display the result:
      </p>

<pre>
def get_citations(text):
  '''Return the set of all citation tags found in a block of text.'''
  return set() # to be done

if __name__ == '__main__':
  test = '''\
Granger's work on graphs \cite{dd-gr2007,gr2009},
particularly ones obeying Snape's Inequality
\cite{ snape87 } (but see \cite{quirrell89}),
has opened up new lines of research.  However,
studies at Unseen University \cite{stibbons2002,                                                                                                       
stibbons2008} highlight several dangers.'''

  print get_citations(test)
<span class="out">set([])</span>
</pre>

      <p>
        Now let's write our function.
        For readability's sake,
        we'll put our patterns at the top and give them memorable names.
        Inside the function,
        we'll pull out all the citations using the first pattern,
        then split each result everywhere there's a comma with optional spaces before or after it.
        We'll stuff all the results into a set, and return that.
        If no matches were found, that set will be empty.
      </p>

<pre>
import re

p_cite = 'cite{\\s*\\b([^}]+)\\b\\s*}'
p_split = '\\s*,\\s*'

def get_citations(text):
  '''Return the set of all citation tags found in a block of text.'''

  result = set()
  match = re.findall(p_cite, text)
  if match:
    for citation in match:
      cites = re.split(p_split, citation)
      for c in cites:
        result.add(c)

  return result
</pre>

      <p>
        We can use one more trick from the regular expression library to make this function more efficient.
        Instead of turning the regular expression into a finite state machine over and over again,
        we can compile the regular expression and save the resulting object:
      </p>

<pre>
import re

p_cite = re.compile('cite{\\s*\\b([^}]+)\\b\\s*}')
p_split = re.compile('\\s*,\\s*')

def get_citations(text):
  '''Return the set of all citation tags found in a block of text.'''

  result = set()
  match = p_cite.findall(text)
  if match:
    for citations in match:
      label_list = p_split.split(citations)
      for label in label_list:
        result.add(label)

  return result
</pre>

      <p class="continue">
        That object has methods with the same names as the functions we've been using from the library,
        like <code>search</code> and <code>findall</code>,
        but if we're using the same pattern over and over again,
        compiling it once and re-using the compiled object is much faster.
      </p>

      <p>
        As you can see,
        the changes required are very small:
        instead of saving the textual representations of our expressions,
        we compile them,
        and then instead of calling the top-level functions from the regular expression library,
        we call the methods of those saved objects.
        The result is a set of all the citations in our test data,
        pulled out with just a dozen lines of code:
      </p>

<pre>
if __name__ == '__main__':
  test = '''\
Granger's work on graphs \cite{dd-gr2007,gr2009},
particularly ones obeying Snape's Inequality
\cite{ snape87 } (but see \cite{quirrell89}),
has opened up new lines of research.  However,
studies at Unseen University \cite{stibbons2002,                                                                                                       
stibbons2008} highlight several dangers.'''

  print get_citations(test)
<span class="out">set(['gr2009', 'stibbons2002', 'dd-gr2007', 'stibbons2008',
       'snape87', 'quirrell89'])</span>
</pre>

      <p>
        Finally, if we are going to compile our regular expressions,
        we can make them even easier to understand
        by using <em>verbose mode</em> to add comments.
        Verbose mode tells Python to ignore whitespace and comments in the regular expression,
        which lets us write patterns like this:
      </p>

<pre>
p_cite = '''
    cite{          # start with literal 'cite{'
    \\s*           # then some optional spaces
    \\b            # up to a start-of-word boundary
    ([^}]+)        # then anything that isn't a closing '}'
    \\b            # then an end-of-word boundary
    \\s*           # and some more optional spaces
    }              # and the closing '}'
'''
matcher = re.compile(p_cite, re.VERBOSE)
</pre>

      <p>
        Documenting patterns like this makes them much easier to fix and extend.
      </p>

    </section>

    <section id="s:summary">

      <h2>Summing Up</h2>

      <p>
        Every regular expressions is actually a little program:
        a piece of data that tells a computer how to behave.
        The steps the computer goes through when executing a Python or Fortran program
        are more complicated than the ones it uses to compile and apply a regular expression,
        but the principles are exactly the same.
      </p>

      <p>
        One last point to take away from this chapter is that
        if we know we are going to use regular expressions to read in data,
        we should choose a format for that data that's easy for regular expressions to match.
        Optional commas,
        tabs that might be repeated,
        and other things that make data easy for people to type in
        actually make it harder for programs to read that data reliably.
        This tension between what's easy for the machine and what's easy for the user never goes away,
        but if we're conscious of it,
        we can find a happy medium.
      </p>

    </section>

  </body>
</html>
