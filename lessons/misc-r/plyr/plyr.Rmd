plyr
========================================================

`plyr` is an R Package for Split-Apply-Combine workflows.  Its functional 
programming model encourages writing reusable functions which can be called 
across varied datasets and frees the analyst/scientist from needing to manage 
for loop indices.  If you are already a savy R user, many of the `*apply` 
functions can be used to cobble together similar functionality as `plyr`.  The 
advantage with `plyr` is that you have a common function naming convention and 
a common set of function parameters, so the functions behave similarly and 
interchangeably.

# Expected background
This lesson assumes basic R knowledge, especially a good understanding of 
`list`, `data.frame` and `array` data types in R.  An understanding of the 
`*apply` functions in base-R is helpful, but not required.  Additionally, it 
will be helpful if you've worked with the base-R function `lm()` for simple 
linear modeling.

# Lesson overview
This lesson should take abour 30-45 minutes to go through.  When you're done you
should have a better understanding of

1. What is `plyr` and when to use it
1. How to select an appropriate `plyr` function based on your input and output 
data types
1. How to write functions for processing splits
1. Work several examples using `list`, `data.frame` and `array` `plyr` 
functions. 

# plyr Functions

plyr has functions for operating on `lists`, `data.frames` and `arrays`.  Each 
function performs:

1. A splitting operation
2. An `apply` where a function is called on each split in turn.
3. A recombination of output data as a single data object.

# Functions continued
The functions are named based on which type of object they expect as input 
([a]rray, [l]ist or [d]ata frame) and which type of data structure should be 
returned as output.

This gives us 9 core functions **ply.  There are an adittional three functions 
which will only perform the split and apply steps, and not any combine step.  
They're named by their input data type and represent null output by a `_` (see 
table)

|INPUT\OUTPUT|Array|Data frame|List|Discarded|
|------------|:---:|:--------:|:--:|--------:|
|Array|aaply|adply|alply|a_ply|
|Data frame|daply|ddply|dlply|d_ply|
|list|laply|ldply|llply|l_ply|

# What can we do with these functions?

```{r}
library(plyr)
head(iris)
iris_mean <- ddply(iris, .(Species), function(df) { 
    data.frame(mean.petal_length=mean(df$Petal.Length), 
              max.petal_length=max(df$Petal.Length)) 
    })
iris_mean
```

## Debrief

### What we did

1. Told plyr we wanted to send in a data.frame of iris data
2. Told it to split (or subset) the iris data.frame by "Species".
3. Wrote an anonymous function to process `df` for each sub-data frame.

### What plyr did for us

1. Coaxed input to a `data.frame` if it wasn't already
2. Performed subsetting operation on unique values of `Species`
3. In-turn fed those three subsets to our user defined function.
4. Took the output and coaxed it back to a `data.frame` if it wasn't already.
5. Combined all rows from all splits into a single data frame.

The steps that plyr performed for us are typically very fragile pieces of code 
in many scientific analysis workflows. plyr is able to give us an *abstraction 
layer* where we don't have to think about the mechanics of accounting for data 
types and specific loop indices.

In this way plyr is a building block for simplifying complex analysis code.


# Models across sites 

Imagine we have 10 sites (labled a-j) where we're making observations of some 
variables x and y.  We'd like to generate linear models for each of the sites 
and look at some summary of the models (slope, intercept, rsquared).  For this 
example we'll just use some random normal data for illustration.

```{r}
set.seed(123) # Set random seed so instructor and students data are the same
x <- rnorm(150)
y <- x + rnorm(150)
site <- rep(c('a','b','c','d','e','f','g','h','i','j'), each=15)
experiment <- data.frame(x=x,y=y,site=site)
head(experiment)

```
We now have a 150-row data set with 10 unique sites labeled a-j.

Now we write a function to perform modeling on each subdataset, and we use 
`dlply()` to take the `experiment` data frame and split it on site, before 
applying the function `model)` to each split.

```{r}
model <- function(df) { 
    lm(y ~ x, data=df)
}

# Feed data into model one-by-one returning models to a list of models.
models <- dlply(experiment, .(site), model)
```

Now we have a list of models, we want to write another plyr expression to 
operate on that list of models and return a data frame of the slope, intercept 
and R-squared values.

```{r}
coefs <- function(model) { 
    c(coef(model), rsquare = summary(model)$r.squared)
}
ldply(models, coefs)
```


# A larger data set

Using the ozone dataset that comes with plyr we can explore a more complicated 
and multi-dimensional example.  The ozone data set is a 3-dimensional array with 
the first two dimensions being latitude and longitude, while the third is a 
monthly time series over 6 years. 

```{r}
overview_loc <- adply(ozone, c(1,2) , summary)
head(overview_loc)
```
For each of the 576 locations we can see some summary univariate statistics 
across the time dimension (based on margins of c(1,2) ).

If we wanted to see the univariate statistics for all of space, at each of the 
72 timesteps, we could run with a margin of 3.

```{r}
summarize_arrayvals <- function(a) { 
  summary(as.vector(a))
  }
overview_temporal <- adply(ozone, 3, summarize_arrayvals)
head(overview_temporal)
```

Notice how the output contains the output of summary with a cbind of the 
dimension that was used for splitting (lat,lon) and (time) respectively.  plyr 
is doing much of the heavy lifting and allowing you to simply write a function 
that operates on the splits in a generalized way.


# Underscore Functions

The functions `a_ply`, `d_ply` and `l_ply` are special case where the split 
function return values are discarded.  This can be useful in cases where your 
split function performs some operation which you persist to disk or a database.

In the below example we use the plotting library `ggplot2` to plot a graph for 
each combination of `Treatment` and `Plant` in the R `CO2` example data set.

```{r, eval = FALSE}
library(plyr)   
library(ggplot2) 
library(lattice) # for ethanol data
data(ethanol)
makeplot <- function (df) { 
    plant <- unique(df$Plant)
    treatment <- unique(df$Treatment)
    title <- paste("CO2 Concentration vs. uptake for ",
                    plant, " with treatment: ", treatment, sep="")
    ggplot(df, aes(x=conc, y=uptake)) + 
            geom_point() + 
            geom_line() + 
            ggtitle(title)
}
pdf('outfile.pdf',width=11, height=8.5)
d_ply(CO2, .(Treatment,Plant), makeplot, .print=TRUE)
dev.off()

``` 

Notice that we open the PDF file before we run `d_ply` and we call .print=TRUE 
to force the `ggplot` statement to be printed to the PDF file.  Also note that 
we split the input data set on two dimensions, `Treatment` and `Plant`, this 
approach can be used to slice larger experiments across many dimensions for 
modeling, plotting or summarization.


# Additional capabilities

## Parallel/Multi-core 

All plyr functions also have a `.parallel` method which will parallelize the 
inner loops of plyr operations.  In order to use `.parallel` you must use a 
package like `doMC` which is appropriate for your operating system. 

## Progress bars

By specifying `.progress = 'text' ` to your plyr function parameters, plyr will 
display a progress bar for long-running plyr operations.

## print
The `*_ply` functions have a `.print` option which will automatically wrap your 
function in a `print()` statement so outputs get written to display devices such
as PDFs, PNGs etc.


# More information
The author of plyr, Hadely Wickham, has an excellent and freely availble paper 
called ["The Split-Apply-Combine Strategy for Data Analysis"](http://www.jstatsoft.org/v40/i01/paper).  
It is an excellent reference for further learning and examples.



