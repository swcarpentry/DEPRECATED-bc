plyr
========================================================

plyr is an R Package for Split-Apply-Combine workflows.  It's functional programming model encourages writing reusable functions which can be called across varied datasets and frees the analyst/scientist from needing to manage for loop indices.

# plyr Functions

plyr has functions for operating on lists, data frames and arrays.  Each function performs:

1. A splitting operation
2. An "apply" where a function is called on each split in turn.
3. A recombination of output data as a single data object.

# Functions continued
The functions are named based on which type of object they expect as input (array, list or data frame) and which type of data structure should be returned as output.

This gives us 9 core functions **ply.  There are an adittional three functions which will only perform the split and apply steps, and not any combine step.  They're named by their input data type and represent null output by a `_` (see table)

|INPUT\OUTPUT|Array|Data frame|List|Discarded|
|------------|:---:|:--------:|:--:|--------:|
|Array|aaply|adply|alply|a_ply|
|Data frame|daply|ddply|dlply|d_ply|
|list|laply|ldply|llply|l_ply|

# What can we do with these functions?

```{r}
library(plyr)
iris_mean <- ddply(iris, .(Species), function(df) { 
    data.frame(mean.petal_length=mean(df$Petal.Length)) 
    })
iris_mean
```

## Debrief

### What we did

1. Told plyr we wanted to send in a data.frame of iris data
2. Told it to split (or subset) the iris data.frame by "Species".
3. Wrote an anonymous function to process `df` for each sub-data frame.

### What plyr did for us

1. Coaxed input to a `data.frame` if it wasn't already
2. Performed subsetting operation on unique values of `Species`
3. In-turn fed those three subsets to our user defined function.
4. Took the output and coaxed it back to a `data.frame` if it wasn't already.

The steps that plyr performed for us are typically very fragile pieces of code in many scientific analysis workflows. plyr is able to give us an *abstraction layer* where we don't have to think about the mechanics of accounting for data types and specific loop indices.

In this way plyr is a building block for simplifying complex scientific analysis code.

# Models across sites 

Imagine we have 10 sites (labled a-j) where we're making observations of some variables x and y.  We'd like to generate linear models for each of the sites and look at some summary of the models (slope, intercept, rsquared).  For this example we'll just use some random normal data for illustration.

```{r}
x <- rnorm(150)
y <- x + rnorm(150)
site <- rep(c('a','b','c','d','e','f','g','h','i','j'), each=15)
experiment <- data.frame(x=x,y=y,site=site)
head(experiment)

```
We now have a 150-row data set with 10 unique sites labeled a-j.

Now we write a function to perform modeling on each subdataset, and we use `dlply()` to take the `experiment` data frame and split it on site, before applying the function `model)` to each split.

```{r}
model <- function(df) { 
    lm(y ~ x, data=df)
}
# Feed data into model one-by-one returining models to a list of models.
models <- dlply(experiment, .(site), model)
```

Now we have a list of models, we want to write another plyr expression to operate on that list of models and return a data frame of the slope, intercept and R-squared values.

```{r}
coefs <- function(model) { 
    c(coef(model), rsquare = summary(model)$r.squared)
}
ldply(models, coefs)
```

As we're working with random normal data, your results are going to be different than the results here.


# A larger data set

Using the ozone dataset that comes with plyr we can explore a more complicated and multi-dimensional example.  The ozone data set is a 3-dimensional array with the first two dimensions being latitude and longitude, while the third is a monthly time series over 6 years. 

```{r}
overview_loc <- adply(ozone, c(1,2) , summary)
head(overview_loc)
```
For each of the 576 locations we can see some summary univariate statistics across the time dimension (based on margins of c(1,2) ).

If we wanted to see the univariate statistics for all of space, at each of the 72 timesteps, we could run with a margin of 3.

```{r}
summarize_arrayvals <- function(a) { 
  summary(as.vector(a))
  }
overview_temporal <- adply(ozone, 3, summarize_arrayvals)
head(overview_temporal)
```

Notice how the output contains the output of summary with a cbind of the dimension that was used for splitting (lat,lon) and (time) respectively.  plyr is doing much of the heavy lifting and allowing you to simply write a function that operates on the splits in a generalized way.


# Additional capabilities

## Parallel/Multi-core 

All plyr functions also have a `.parallel` method which will parallelize the inner loops of plyr operations.  In order to use `.parallel` you must use a package like `doMC` which is appropriate for your operating system. 

## Progress bars

By specifying `.progress = 'text' ` to your plyr function parameters, plyr will display a progress bar for long-running plyr operations.

## print
The `*_ply` functions have a `.print` option which will automatically wrap your function in a `print()` statement so outputs get written to display devices such as PDFs, PNGs etc.


# More information
The author of plyr, Hadely Wickham, has an excellent and freely availble paper called ["The Split-Apply-Combine Strategy for Data Analysis"](http://www.jstatsoft.org/v40/i01/paper).  It is an excellent reference for further learning and examples.



